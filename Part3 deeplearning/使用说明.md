# Part3 模块使用说明

## 1. 概述

Part3 是基于机器学习的智能检测模块，用于预测 HTTP 请求是否会被目标网站的 WAF 拦截。该模块集成了多种机器学习算法，支持模型训练、预测和评估功能。

## 2. 环境准备

### 2.1 安装依赖

```bash
pip install -r requirements.txt
```

### 2.2 依赖说明

- scikit-learn: 传统机器学习算法
- xgboost/lightgbm: 梯度提升算法
- pandas/numpy: 数据处理
- matplotlib/seaborn: 数据可视化
- spacy/transformers: NLP处理

## 3. 模块详解

### 3.1 数据处理模块 (data_processor.py)

#### 功能说明
负责处理来自 Part1 和 Part2 的输入数据，生成机器学习模型所需的训练数据和特征。

#### 主要函数
- `process_waf_fingerprint()`: 处理 Part1 的 WAF 指纹识别结果
- `extract_features()`: 从 HTTP 请求中提取特征
- `generate_training_data()`: 根据规则数据生成训练样本
- `load_dataset()`: 加载数据集
- `preprocess_data()`: 数据预处理

#### 使用示例
```python
from data_processor import DataProcessor

processor = DataProcessor()
features = processor.extract_features(http_request)
```

### 3.2 模型定义模块 (models.py)

#### 功能说明
定义了用于 WAF 拦截预测的各种机器学习模型，包括传统机器学习模型。

#### 支持的模型类型
- LogisticRegressionModel: 逻辑回归模型
- RandomForestModel: 随机森林模型
- XGBoostModel: XGBoost 模型

#### 使用示例
```python
from models import ModelFactory

# 创建模型
model = ModelFactory.create_model("random_forest")
# 训练模型
model.train(X_train, y_train)
# 预测
predictions = model.predict(X_test)
```

### 3.3 模型训练器模块 (trainer.py)

#### 功能说明
负责模型的训练、验证和测试过程，包括超参数调优、交叉验证、模型选择等功能。

#### 主要函数
- `train_model()`: 训练模型
- `cross_validate()`: 交叉验证
- `hyperparameter_tuning()`: 超参数调优
- `select_best_model()`: 模型选择

#### 使用示例
```python
from trainer import ModelTrainer

trainer = ModelTrainer("xgboost")
trainer.train_model(X_train, y_train)
```

### 3.4 预测器模块 (predictor.py)

#### 功能说明
使用训练好的模型对新的 HTTP 请求进行拦截预测，支持不同 WAF 类型的特化模型和通用模型。

#### 主要函数
- `load_model()`: 加载模型
- `select_model_by_waf()`: 根据 WAF 类型选择模型
- `predict()`: 预测单个请求
- `batch_predict()`: 批量预测

#### 使用示例
```python
from predictor import Predictor

predictor = Predictor()
predictor.load_model("model.pkl")
result = predictor.predict(http_request)
```

### 3.5 模型评估模块 (evaluator.py)

#### 功能说明
负责评估训练好的模型性能，包括各种评估指标的计算和可视化。

#### 主要函数
- `calculate_metrics()`: 计算评估指标
- `plot_roc_curve()`: 绘制 ROC 曲线
- `plot_confusion_matrix()`: 绘制混淆矩阵
- `generate_report()`: 生成评估报告

#### 使用示例
```python
from evaluator import Evaluator

evaluator = Evaluator()
metrics = evaluator.calculate_metrics(y_true, y_pred)
```

### 3.6 配置模块 (config.py)

#### 功能说明
定义了 Part3 的各种配置参数，包括模型参数、数据处理参数、训练参数等。

#### 主要配置项
- MODEL_CONFIGS: 模型配置
- DATA_CONFIGS: 数据配置
- TRAINING_CONFIGS: 训练配置
- DEFAULT_FEATURES: 默认特征列表

#### 使用示例
```python
from config import MODEL_CONFIGS

rf_params = MODEL_CONFIGS["random_forest"]
```

### 3.7 工具模块 (utils.py)

#### 功能说明
提供 Part3 所需的通用工具函数，包括文件操作、日志记录、数据转换等。

#### 主要函数
- `load_json()/save_json()`: JSON 文件读写
- `setup_logger()`: 日志记录器设置
- `http_request_to_dict()/dict_to_http_request()`: HTTP 请求转换
- `normalize_text()`: 文本标准化

## 4. 运行模式

### 4.1 命令行参数

主程序支持以下命令行参数：

```bash
python main.py [--mode MODE] [--model-type MODEL_TYPE] [--data-path DATA_PATH] [--model-path MODEL_PATH] [--output-path OUTPUT_PATH]
```

参数说明：
- `--mode`: 运行模式，可选 train/predict/evaluate，默认为 predict
- `--model-type`: 模型类型，可选 logistic_regression/random_forest/xgboost
- `--data-path`: 数据路径
- `--model-path`: 模型路径
- `--output-path`: 输出路径

### 4.2 训练模式

```bash
python main.py --mode train --model-type random_forest --data-path /path/to/data
```

### 4.3 预测模式

```bash
python main.py --mode predict --model-path /path/to/model --data-path /path/to/requests
```

### 4.4 评估模式

```bash
python main.py --mode evaluate --model-path /path/to/model --data-path /path/to/test_data
```

## 5. 与 Part1 和 Part2 的集成

### 5.1 Part1 集成
- 利用 WAF 指纹识别结果选择合适的特化模型
- 根据识别出的 WAF 类型调整特征提取策略

### 5.2 Part2 集成
- 利用规则解析结果生成高质量的训练数据
- 基于规则依赖关系提取高级特征
- 使用规则语义分析增强模型理解能力

## 6. 模型选择建议

### 6.1 初期阶段
使用逻辑回归或随机森林快速验证特征有效性

### 6.2 中期阶段
采用 XGBoost 或 LightGBM 提升预测性能

## 7. 注意事项

1. 确保数据质量：训练数据的质量直接影响模型性能
2. 特征工程重要性：合理的特征设计是模型成功的关键
3. 模型评估：使用多种指标全面评估模型性能
4. 持续优化：根据实际使用情况持续优化模型