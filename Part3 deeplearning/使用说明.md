# Part3 模块使用说明

## 1. 概述

Part3 是基于传统机器学习的智能检测模块，用于预测 HTTP 请求是否会被目标网站的 WAF 拦截。该模块集成了多种传统机器学习算法，支持模型训练、预测和评估功能，并能根据WAF类型自动选择最适合的模型。

## 2. 环境准备

### 2.1 安装依赖

```bash
pip install -r requirements.txt
```

### 2.2 依赖说明

- scikit-learn: 传统机器学习算法
- xgboost: 梯度提升算法
- pandas/numpy: 数据处理
- matplotlib/seaborn: 数据可视化（部分功能待实现）

## 3. 模块详解

### 3.1 数据处理模块 (data_processor.py)

#### 功能说明
负责处理来自 Part1 和 Part2 的输入数据，生成机器学习模型所需的训练数据和特征。

#### 主要函数
- `process_waf_fingerprint()`: 处理 Part1 的 WAF 指纹识别结果
- `extract_features()`: 从 HTTP 请求中提取特征
- `generate_training_data()`: 根据规则数据生成训练样本 *(已实现对Part2数据的支持)*
- `load_dataset()`: 加载数据集 *(支持CSV格式)*
- `preprocess_data()`: 数据预处理 *(支持去重和缺失值处理)*

#### 使用示例
```python
from data_processor import DataProcessor

processor = DataProcessor()
features = processor.extract_features(http_request)

# 加载数据集
data = processor.load_dataset("data.csv")

# 数据预处理
processed_data = processor.preprocess_data(data)
```

#### Part2规则数据格式说明

Part2模块输出的规则数据应包含以下字段：

1. **rule_info**: 规则基本信息
   - `id`: 规则ID
   - `phase`: 处理阶段
   - `variables`: 匹配变量列表
   - `operator`: 操作符
   - `pattern`: 匹配模式
   - `actions`: 动作列表
   - `tags`: 标签列表
   - `message`: 规则消息
   - `severity`: 严重级别
   - `is_chain`: 是否为链式规则

2. **semantic_analysis**: 语义分析结果
   - `attack_types`: 攻击类型分类
   - `rule_classification`: 规则分类结果

3. **dependency_analysis**: 依赖分析结果
   - `variable_dependencies`: 变量依赖
   - `marker_dependencies`: 标记依赖
   - `include_dependencies`: 包含依赖

### 3.2 模型定义模块 (models.py)

#### 功能说明
定义了用于 WAF 拦截预测的各种传统机器学习模型。

#### 支持的模型类型
- LogisticRegressionModel: 逻辑回归模型
- RandomForestModel: 随机森林模型
- XGBoostModel: XGBoost 模型

#### 使用示例
```python
from models import ModelFactory

# 创建模型
model = ModelFactory.create_model("random_forest")
# 训练模型
model.train(X_train, y_train)
# 预测
predictions = model.predict(X_test)
```

### 3.3 模型训练器模块 (trainer.py)

#### 功能说明
负责模型的训练、验证和测试过程，包括交叉验证、模型选择等功能。

#### 主要函数
- `train_model()`: 训练模型
- `cross_validate()`: 交叉验证 *(使用分层K折交叉验证)*
- `hyperparameter_tuning()`: 超参数调优 *(待实现)*
- `select_best_model()`: 模型选择 *(根据WAF类型选择最佳模型)*
- `evaluate_model()`: 模型评估
- `save_model()`: 保存模型

#### 使用示例
```python
from trainer import ModelTrainer

trainer = ModelTrainer("xgboost")
trainer.train_model(X_train, y_train)

# 交叉验证
cv_scores = trainer.cross_validate(X_train, y_train, cv_folds=5)

# 模型选择
best_model = trainer.select_best_model(models, waf_type="modsecurity")
```

### 3.4 预测器模块 (predictor.py)

#### 功能说明
使用训练好的模型对新的 HTTP 请求进行拦截预测，支持不同 WAF 类型的特化模型和通用模型。

#### 主要函数
- `load_model()`: 加载模型
- `select_model_by_waf()`: 根据 WAF 类型选择模型
- `predict()`: 预测单个请求
- `batch_predict()`: 批量预测

#### 使用示例
```python
from predictor import Predictor

predictor = Predictor()
predictor.load_model("modsecurity_model.pkl", "modsecurity")  # 加载ModSecurity特化模型
predictor.load_model("generic_model.pkl", "generic")  # 加载通用模型
result = predictor.predict(http_request)
```

### 3.5 模型评估模块 (evaluator.py)

#### 功能说明
负责评估训练好的模型性能，包括各种评估指标的计算。

#### 主要函数
- `calculate_metrics()`: 计算评估指标 *(支持准确率、精确率、召回率、F1分数和AUC)*
- `plot_roc_curve()`: 绘制ROC曲线 *(待实现)*
- `plot_confusion_matrix()`: 绘制混淆矩阵 *(待实现)*
- `generate_report()`: 生成评估报告 *(待实现)*

#### 使用示例
```python
from evaluator import Evaluator

evaluator = Evaluator()
metrics = evaluator.calculate_metrics(y_true, y_pred, y_pred_proba)
```

### 3.6 配置模块 (config.py)

#### 功能说明
定义了 Part3 的各种配置参数，包括模型参数、数据处理参数、训练参数等。

#### 主要配置项
- MODEL_CONFIGS: 模型配置
- DATA_CONFIGS: 数据配置
- TRAINING_CONFIGS: 训练配置
- DEFAULT_FEATURES: 默认特征列表

#### 使用示例
```python
from config import MODEL_CONFIGS

rf_params = MODEL_CONFIGS["random_forest"]
```

### 3.7 工具模块 (utils.py)

#### 功能说明
提供 Part3 所需的通用工具函数，包括文件操作、日志记录、HTTP请求处理等。

#### 主要函数
- `load_json()/save_json()`: JSON 文件读写 *(支持UTF-8编码和格式化输出)*
- `setup_logger()`: 日志记录器设置 *(已实现)*
- `http_request_to_dict()/dict_to_http_request()`: HTTP 请求转换 *(已实现)*
- `normalize_text()`: 文本标准化 *(已实现)*
- `encode_payload()/decode_payload()`: Payload编码解码 *(已实现)*

#### 使用示例
```python
from utils import setup_logger, http_request_to_dict, dict_to_http_request

# 设置日志
logger = setup_logger("my_logger", "app.log")
logger.info("这是一条日志信息")

# HTTP请求处理
http_request_str = "GET /index.html HTTP/1.1\r\nHost: example.com\r\n\r\n"
request_dict = http_request_to_dict(http_request_str)
print(request_dict)

# 重新构建HTTP请求
reconstructed_request = dict_to_http_request(request_dict)
print(reconstructed_request)
```

## 4. 运行模式

### 4.1 命令行参数

主程序支持以下命令行参数：

```bash
python main.py [--mode MODE] [--model-type MODEL_TYPE] [--data-path DATA_PATH] [--model-path MODEL_PATH] [--output-path OUTPUT_PATH] [--waf-type WAF_TYPE] [--rules-data-path RULES_DATA_PATH]
```

参数说明：
- `--mode`: 运行模式，可选 train/predict/evaluate，默认为 predict
- `--model-type`: 模型类型，可选 logistic_regression/random_forest/xgboost
- `--data-path`: 数据路径
- `--model-path`: 模型路径
- `--output-path`: 输出路径
- `--waf-type`: WAF类型，可选 modsecurity/generic，用于训练模式
- `--rules-data-path`: Part2规则数据路径（JSON格式）

### 4.2 训练模式

```bash
# 使用Part2规则数据训练ModSecurity特化模型
python main.py --mode train --model-type xgboost --waf-type modsecurity --rules-data-path detailed_rules_report.json --model-path modsecurity_model.pkl

# 训练通用模型
python main.py --mode train --model-type random_forest --waf-type generic --rules-data-path detailed_rules_report.json --model-path generic_model.pkl

# 使用传统CSV数据训练
python main.py --mode train --model-type xgboost --data-path training_data.csv --model-path model.pkl
```

### 4.3 预测模式

```bash
# 使用指定模型进行预测
python main.py --mode predict --model-path modsecurity_model.pkl --waf-info-path waf_info.json

# 自动选择模型进行预测
python main.py --mode predict --waf-info-path waf_info.json
```

### 4.4 评估模式

```bash
python main.py --mode evaluate --model-path modsecurity_model.pkl --data-path test_data.csv
```

## 5. 模型选择策略

Part3实现了智能模型选择机制：

1. **ModSecurity特化模型**：当检测到目标网站使用ModSecurity时使用
2. **通用模型**：处理所有其他WAF类型
3. **默认模型**：当特化模型不可用时的备用选择

在预测时，系统会根据WAF指纹信息自动选择最适合的模型。


我需要综合分析项目的文件结构和功能，提供一个全面的使用方法说明。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
我需要按照计划逐步完成任务，首先查看models.py文件了解模型工厂的实现。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
我需要查看models.py文件，了解模型工厂的实现细节。
        
            
toolName: view_files
            
status: success
          
            
filePath: d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/models.py
          
我已经完成了models.py文件的查看，现在需要查看predictor.py文件，了解预测功能的实现。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
我需要查看predictor.py文件，了解预测功能的实现细节。
        
            
toolName: view_files
            
status: success
          
            
filePath: d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/predictor.py
          
我已经完成了predictor.py文件的查看，现在需要查看utils.py文件，了解工具函数。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
我需要查看utils.py文件，了解项目中使用的工具函数。
        
            
toolName: view_files
            
status: success
          
            
filePath: d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/utils.py
          
我已经完成了utils.py文件的查看，现在需要整理项目的使用方法、功能和输出。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
我已经完成了对项目关键文件的查看，现在可以整理项目的使用方法、功能和输出。
        
            
toolName: todo_write
            
status: success
          
Todos updated: 4 items
          
# WAF_scan-analysis-tool Part3 深度学习模块使用说明

## 项目概述
Part3是WAF_scan-analysis-tool的深度学习模块，用于训练机器学习模型来预测WAF（Web应用防火墙）是否会拦截特定的HTTP请求。该模块支持使用Part2的规则分析结果作为训练数据，并提供模型训练、预测和评估功能。

## 主要功能

### 1. 数据处理功能
- **规则数据加载**：支持从Part2的JSON格式规则报告中加载数据
- **训练样本生成**：根据规则数据自动生成正样本（会被拦截的请求）和负样本（正常请求）
- **特征提取**：从HTTP请求中提取多种特征，包括：
  - URL特征（长度、参数数量、特殊字符数等）
  - 请求方法特征
  - 响应状态特征
  - 请求体特征
  - 请求头特征
  - 攻击模式特征（SQL注入、XSS、LFI等）

### 2. 模型训练功能
- **多模型支持**：支持三种机器学习算法
  - 逻辑回归(Logistic Regression)
  - 随机森林(Random Forest)
  - XGBoost
- **参数配置**：可通过命令行参数或配置文件设置模型参数
- **模型保存**：训练完成后自动保存模型到指定路径

### 3. 模型预测功能
- **单请求预测**：对单个HTTP请求进行拦截预测
- **批量预测**：支持批量处理多个HTTP请求
- **WAF类型适配**：根据WAF类型选择合适的模型（特化模型或通用模型）
- **置信度输出**：提供预测结果的置信度

### 4. 模型评估功能
- **性能指标计算**：准确率(accuracy)、精确率(precision)、召回率(recall)、F1分数
- **交叉验证**：支持5折交叉验证
- **评估报告**：生成详细的评估报告

### 5. 辅助功能
- **日志记录**：详细记录训练、预测和评估过程
- **工具函数**：提供JSON文件操作、HTTP请求转换、文本标准化等工具函数

## 使用方法

### 命令行参数
| 参数 | 描述 | 可选值 | 默认值 |
|------|------|--------|--------|
| --mode | 运行模式 | train/predict/evaluate | predict |
| --model-type | 模型类型 | logistic_regression/random_forest/xgboost | random_forest |
| --data-path | 数据路径（CSV格式） | - | - |
| --rules-data-path | Part2规则数据路径（JSON格式） | - | - |
| --model-path | 模型保存/加载路径 | - | 基于WAF类型的默认路径 |
| --waf-type | WAF类型 | modsecurity/generic | generic |
| --waf-info-path | WAF指纹信息路径（JSON格式） | - | - |

### 1. 训练模式
使用Part2的规则数据生成训练样本并训练模型：

```bash
python "d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/main.py" --mode train --rules-data-path "path/to/detailed_rules_report.json" --model-type random_forest
```

**输出**：
- 训练日志（控制台和日志文件）
- 训练样本数量统计
- 模型训练进度
- 训练完成的模型文件（如：generic_model.pkl）

### 2. 预测模式
使用训练好的模型对HTTP请求进行预测：

```bash
python "d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/main.py" --mode predict --model-path "generic_model.pkl" --waf-info-path "waf_info.json"
```

**输出**：
- 预测结果（0=不拦截，1=拦截）
- 预测置信度
- 预测日志

### 3. 评估模式
评估训练好的模型性能：

```bash
python "d:/CODING/Repository/WAF_scan-analysis-tool/Part3 deeplearning/part3_waf_ml/main.py" --mode evaluate --model-path "generic_model.pkl" --data-path "test_data.csv"
```

**输出**：
- 测试数据加载信息
- 模型评估指标（准确率、精确率、召回率、F1分数）
- 评估日志

## 项目结构

```
part3_waf_ml/
├── main.py          # 主程序入口
├── trainer.py       # 模型训练器
├── data_processor.py # 数据处理器
├── models.py        # 模型定义
├── predictor.py     # 预测器
├── utils.py         # 工具函数
├── config.py        # 配置文件
└── logs/            # 日志文件目录
```

## 输出示例

### 训练模式输出
```
进入训练模式...
正在加载Part2规则数据: path/to/detailed_rules_report.json
正在根据规则数据生成训练样本...
生成训练数据完成，共 3635 个样本
开始训练random_forest模型，训练数据形状：X_train=(3635, 16), y_train=(3635,)
随机森林模型训练完成
模型已保存到: generic_model.pkl
训练模式完成
```

### 预测模式输出
```
进入预测模式...
成功加载generic模型: generic_model.pkl
预测完成，结果: 1, 置信度: 0.8571
预测模式完成
```

### 评估模式输出
```
进入评估模式...
正在加载测试数据: test_data.csv
测试数据加载完成，共 1000 个样本，16 个特征
测试数据形状: X_test=(1000, 16), y_test=(1000,)
开始评估模型，测试数据形状：X_test=(1000, 16), y_test=(1000,)
模型评估完成，指标：{'accuracy': 0.9240, 'precision': 0.9123, 'recall': 0.9356, 'f1': 0.9238}
评估模式完成
```

## 注意事项
1. 训练模式需要Part2的详细规则报告（JSON格式）
2. 模型默认保存在当前工作目录
3. 预测模式需要先训练好模型或提供已训练好的模型文件
4. 评估模式需要测试数据和训练好的模型
5. 所有操作都会生成详细的日志文件，便于调试和分析

通过以上功能，您可以使用Part3模块训练WAF拦截预测模型，并利用训练好的模型对HTTP请求进行拦截预测，为WAF的配置和优化提供参考。